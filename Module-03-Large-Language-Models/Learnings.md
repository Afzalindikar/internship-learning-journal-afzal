# Module 03 – Key Learnings

## WEEK 3 - DAY 1

- Understood internal working of Transformers and self-attention.
- Learned how embeddings convert text into vectors.
- Implemented RAG pipeline using vector databases.
- Compared pure vector search vs hybrid RAG.
- Learned Base64 encoding for image processing.
- Built simple function calling system (Travel Agent example).
- Understood schema-based structured outputs.
- Practiced prompt engineering techniques.
- Evaluated LLM outputs using regression testing.
- Learned cost optimization strategies for production systems.


# Week 3 – Day 2 

- Learned how text is converted into numerical vectors.
- Similar meaning → similar vectors.
- Used embeddings for semantic similarity search.
- Implemented cosine similarity.
- Understood dot product and vector norm.
- Used NumPy to calculate similarity.
- Retrieved top-5 most relevant chunks.
- Large documents must be split into smaller chunks.
- Instead of keyword search, used embedding-based search.
- Compared query embedding with stored embeddings.
- Sorted results by similarity score.
- Learned that embeddings can be generated for both text and images.
- Understood use of models like Nomic AI.
- Images are encoded using Base64 before sending via API.
- Used HTTPX for async API requests.
- Implemented timeout handling.
- Ensured JSON-safe formatting.
- Managed API keys using environment variables (.bashrc).
- Store embeddings once.
- Retrieve only top-5 chunks.
- Avoid sending full documents to LLM.
- Use hybrid RAG for better accuracy.

